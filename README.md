# PdfChatBot

ğŸš€ Features

âœ… Upload and process PDF files
âœ… Extract and store embeddings in FAISS vector store
âœ… Query the document content with natural language
âœ… Stream responses using an LLM (Hugging Face)
âœ… Modular and scalable backend with FastAPI

Project Structure 
fastapi-pdf-chatbot/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.py             # Chat and upload endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py           # Environment configurations
â”‚   â”‚   â”œâ”€â”€ llm_service.py      # sak_llm() and LLM interaction logic
â”‚   â”‚   â””â”€â”€ pdf_service.py      # PDF parsing and embedding logic
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ vector_store.py     # FAISS vector database logic
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models for requests/responses
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/                # Folder to store uploaded PDFs
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/yourusername/fastapi-pdf-chatbot.git
cd fastapi-pdf-chatbot

2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate  # for Linux/Mac
venv\Scripts\activate     # for Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ”§ Environment Variables
Create a .env file in the root directory:

HF_MODEL_URL="http://127.0.0.1:8000" 

Start the FastAPI app:
uvicorn app.main:app --reload

Then open your browser at:
http://127.0.0.1:8000

ğŸ§° Dependencies

Key packages:

FastAPI â€“ API framework
LangChain â€“ LLM orchestration
FAISS â€“ Vector database
PyPDF2 â€“ PDF parsing
Uvicorn â€“ ASGI server
